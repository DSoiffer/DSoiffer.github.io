---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! I'm Duncan Soiffer, a 2024 - 2025 (December) Master's in Machine Learning student at Carnegie Mellon University. Previously, I was an undergraduate at Worcester Polytechnic Institute from 2020-2024, where I majored in computer science and math. I am broadly interested in all aspects of machine learning, and especially interested in core methods.

I currently work in [Professor Virginia Smith](https://www.cs.cmu.edu/~smithv/)'s lab, where my primary project is on extending agreement-based cascading to generative language tasks (where agreement is difficult to quantify). On the side, I'm also experimenting with a project on exploring inductive bias and the solution space of representation learning methods through a novel (but as-of-yet unproven) lens.

Besides this, I have previously worked on reinforcement learning, AI for science, and on a cubesatellite. I'm most proud of my Major Qualifying Project (undergraduate thesis) at WPI. Along with fellow undergraduates Andrew Salls and [Chase Miller](thecpmills.com), and supervised by Professors Daniel Reichman, Gábor Sárközy, and George Heineman, we improved the best known lower bounds on the [Chvátal–Sankoff constants](https://en.wikipedia.org/wiki/Chv%C3%A1tal%E2%80%93Sankoff_constants) and additionally created a [website](https://statistics-of-subsequences.github.io/) to help teach and explore the Longest Common Subsequence problem more generally.